{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on pineapple\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "HOSTNAME = socket.gethostname()\n",
    "print('Running on', HOSTNAME)\n",
    "if(HOSTNAME != \"pineapple\"):\n",
    "    raise ValueError(\"Please run on pineapple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_file = '/data/junting/DL4CV_COMSW4995_006/final_project/training_gt.csv'\n",
    "validation_target_file = '/data/junting/DL4CV_COMSW4995_006/final_project/validation_gt.csv'\n",
    "\n",
    "# first load ground truth into a numpy file\n",
    "train_gt_np = np.genfromtxt(train_target_file, delimiter=',', dtype=object)\n",
    "validation_gt_np = np.genfromtxt(validation_target_file, delimiter=',', dtype=object)\n",
    "\n",
    "# get a list of mp4 names\n",
    "train_mp4_names = train_gt_np[1:, 0]\n",
    "validation_mp4_names = validation_gt_np[1:, 0]\n",
    "\n",
    "# construct a dictionary for ground truth\n",
    "train_gt = {}\n",
    "validation_gt = {}\n",
    "for i in range(1,train_gt_np.shape[0]):\n",
    "    name = train_gt_np[i, 0]\n",
    "    scores = train_gt_np[i, 1:].astype(float)\n",
    "    train_gt[name] = scores\n",
    "for i in range(1,validation_gt_np.shape[0]):\n",
    "    name = validation_gt_np[i, 0]\n",
    "    scores = validation_gt_np[i, 1:].astype(float)\n",
    "    validation_gt[name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frames_path = '/data/junting/ECCV/trainframes'\n",
    "validation_frames_path = '/data/junting/ECCV/validationframes'\n",
    "\n",
    "train_audiofeat_path = '/data/junting/ECCV/trainaudiofeat/'\n",
    "validation_audiofeat_path = '/data/junting/ECCV/validationaudiofeat/'\n",
    "\n",
    "def get_next_batch(batch_size):\n",
    "    batch = {}\n",
    "    \n",
    "    while True:\n",
    "        # randomly choose a list of mp4 names to consist the batch\n",
    "        mp4_names = np.random.permutation(train_mp4_names)[0:batch_size]\n",
    "        \n",
    "        # get video batches -> batch_size * 6 * 112 * 112 * 3\n",
    "        video = np.zeros((batch_size, 6, 112, 112, 3))\n",
    "        for batch_num, mp4 in enumerate(mp4_names):            \n",
    "            all_frames = os.listdir(os.path.join(train_frames_path, mp4.replace('.mp4', '')))\n",
    "            num_frames = len(all_frames) # int\n",
    "            interval = num_frames/6\n",
    "            for i in range(0, 6):\n",
    "                index = i*interval + np.random.randint(1, interval+1)\n",
    "                frame_name = 'frame_det_00_%06d.png' % (index)\n",
    "                frame = mpimg.imread(os.path.join(train_frames_path, mp4.replace('.mp4', ''), frame_name))\n",
    "                video[batch_num, i] = frame\n",
    "        \n",
    "        # get audio batches -> batch_size * 6 * 68\n",
    "        audio = np.zeros((batch_size, 6, 68))\n",
    "        for batch_num, mp4 in enumerate(mp4_names):\n",
    "            audiofeat_name = mp4+'.wav.csv'\n",
    "            audio[batch_num] = np.genfromtxt(os.path.join(train_audiofeat_path, audiofeat_name), delimiter=',')\n",
    "            \n",
    "        # get ground truth -> batch_size * 6 * 5 (copied 5 times)\n",
    "        gt = np.zeros((batch_size, 6, 5))\n",
    "        for batch_num, mp4 in enumerate(mp4_names):\n",
    "            gt[batch_num] = np.tile(np.array(train_gt[mp4]), (6, 1))\n",
    "\n",
    "        batch['gt'] = gt\n",
    "        batch['audio'] = audio\n",
    "        batch['video'] = video\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d9b9a7ddcf23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-23f1f4802a6e>\u001b[0m in \u001b[0;36mget_next_batch\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp4\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp4_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mall_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_frames_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mnum_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_frames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "generator = get_next_batch(10)\n",
    "for batch in generator:\n",
    "    print(batch['video'].shape)\n",
    "    print(batch['audio'].shape)\n",
    "    print(batch['gt'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PARAMS(object):\n",
    "    base_output_dir = \"/data/junting/DL4CV_COMSW4995_006/final_project/models\"\n",
    "    #learning rate\n",
    "    learningRate = 0.05\n",
    "    #weightDecay = 5e-4\n",
    "    learningRateDecayStep = 2500\n",
    "    momentum = 0.9\n",
    "    learningRateDecay = 0.96\n",
    "    \n",
    "    #hyper settings\n",
    "    batchSize = 128\n",
    "    forceNewModel = True\n",
    "    targetScaleFactor = 1\n",
    "    nGPUs = 1\n",
    "    GPU = 1\n",
    "    LSTM = True\n",
    "    useCuda = True\n",
    "    #6000/128 * 10000\n",
    "    nb_batches = 400000\n",
    "    nb_show = 100\n",
    "    nb_validate = 500\n",
    "    nb_save = 1000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logdirs_and_modelname(PARAMS):\n",
    "    \"\"\"Set log directories and model names.\"\"\"\n",
    "    log_output_dir = \"log\"\n",
    "    log_output_dir += \"_\" + str(PARAMS.learningRate)\n",
    "    log_output_dir += \"_\" + str(PARAMS.learningRateDecayStep)\n",
    "    log_output_dir += \"_\" + str(PARAMS.learningRateDecay)\n",
    "    output_dir = os.path.join(PARAMS.base_output_dir, log_output_dir)\n",
    "    output_model_name = \"JingxiNet\"\n",
    "    return output_dir, output_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error converting shape to a TensorShape: Dimension -1 must be >= 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    848\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# Got a list of dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mas_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_iter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mas_dimension\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    396\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dimension %d must be >= 0\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension -1 must be >= 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d339fbcfb406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mjx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJingxiNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mjx_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m#time stamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mstart_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/junting/DL4CV_COMSW4995_006/final_project/src/model_LSTMSpatial.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ground_truth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_pl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m68\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"audio_pl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_pl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"video_pl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0mevaluated\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m   \"\"\"\n\u001b[0;32m-> 1599\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   3085\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3086\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3087\u001b[0;31m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3088\u001b[0m   \u001b[0m_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pineapplepython/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_shape\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     raise ValueError(\"Error converting %s to a TensorShape: %s.\" % (arg_name,\n\u001b[0;32m--> 149\u001b[0;31m                                                                     e))\n\u001b[0m\u001b[1;32m    150\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error converting shape to a TensorShape: Dimension -1 must be >= 0."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    import time\n",
    "    import tensorflow as tf\n",
    "    from model_LSTMSpatial import JingxiNet\n",
    "    \n",
    "    output_log_dir, output_model_name = get_logdirs_and_modelname(PARAMS)\n",
    "    \n",
    "    with tf.variable_scope(output_model_name, reuse=tf.AUTO_REUSE):\n",
    "        with tf.device('/gpu:0'):\n",
    "            #global step\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            jx_model = JingxiNet()\n",
    "            jx_model.create_model()\n",
    "            #time stamp \n",
    "            start_ts = time.time()\n",
    "            #loss\n",
    "            #loss = tf.nn.l2_loss(jx_model.frame_features - jx_model.ground_truth)\n",
    "            loss = tf.reduce_sum(tf.square(jx_model.frame_features - jx_model.ground_truth)) / PARAMS.batchSize\n",
    "            #learning rate\n",
    "            lr = tf.train.exponential_decay(PARAMS.learningRate, global_step,PARAMS.learningRateDecayStep,PARAMS.learningRateDecay,staircase=True)\n",
    "            moment = tf.train.moment()\n",
    "            #optimazation\n",
    "            #did not use weight decay!!!!!\n",
    "            train_jx = tf.train.MomentumOptimizer(lr, PARAMS.momentum).minimize(loss,global_step=global_step)\n",
    "            \n",
    "            \n",
    "            sess = tf.InteractiveSession()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"Graph defined and initialized in {}s.\".format(time.time() - start_ts))\n",
    "            \n",
    "    #cpu work    \n",
    "    with tf.device('/cpu:0'):\n",
    "        training_summary = tf.summary.scalar(\"training loss\", loss)\n",
    "        validation_summary = tf.summary.scalar(\"validation loss\", loss)\n",
    "        #learning_rate = tf.summary.scalar(\"learning_rate\", lr)\n",
    "        all_summary = tf.summary.merge_all()\n",
    "            \n",
    "    print(scope_variables(\"\"))\n",
    "    saver = tf.train.Saver(scope_variables(\"\"))\n",
    "    train_writer = tf.summary.FileWriter(output_log_dir, sess.graph)\n",
    "    #start training\n",
    "    count_batch = 0\n",
    "    #JINGXI: please return current_batch to be a structure such as:\n",
    "    #current_batch = {'audio': audio_feat, 'image': image_feat, 'gt': ground_truth}\n",
    "    for current_batch in get_next_batch(PARAMS.batch_size):\n",
    "        #run session\n",
    "        sess.run(train_jx, feed_dict={jx_model.audio_pl: current_batch['audio'], \n",
    "                                      jx_model.video_pl: current_batch['image'],  \n",
    "                                      jx_model.ground_truth: current_batch['gt']})\n",
    "        \n",
    "        #show result\n",
    "        if count_batch % PARAMS.nb_show == 0:\n",
    "            #train loss\n",
    "            train_summ, train_loss = sess.run([training_summary, loss], \n",
    "                                              feed_dict={jx_model.audio_pl: current_batch['audio'], \n",
    "                                                         jx_model.video_pl: current_batch['image'],  \n",
    "                                                         jx_model.ground_truth: current_batch['gt']})\n",
    "            train_writer.add_summary(train_summ, count_batch)\n",
    "            print(\"step %d/%d: train loss: %f\" % (count_batch, PARAMS.nb_batches,train_loss))\n",
    "        \n",
    "        if count_batch % PARAMS.nb_validate == 0:\n",
    "            #validation loss\n",
    "            validation_summ, validation_loss = sess.run([validation_summary, loss], \n",
    "                                              feed_dict={jx_model.audio_pl: validation_set['audio'], \n",
    "                                                         jx_model.video_pl: validation_set['image'],  \n",
    "                                                         jx_model.ground_truth: validation_set['gt']})\n",
    "            train_writer.add_summary(validation_summ, count_batch)\n",
    "            print(\"step %d/%d: validation loss: %f\" % (count_batch, PARAMS.nb_batches,validation_loss))\n",
    "\n",
    "        #save model\n",
    "        if count_batch % PARAMS.nb_save == 0:\n",
    "            saver.save(sess, os.path.join(PARAMS.base_output_dir, output_model_name+'_'+str(count_batch)))\n",
    "        \n",
    "        count_batch += 1\n",
    "        #end condition\n",
    "        if count_batch > PARAMS.nb_batches:\n",
    "            break\n",
    "\n",
    "    # Save final model\n",
    "    saver.save(sess, os.path.join(PARAMS.base_output_dir, output_model_name))\n",
    "\n",
    "    \n",
    "    #TODO: validation not done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
